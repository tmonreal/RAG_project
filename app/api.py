"""
This file serves as the FastAPI backend where users can send questions, 
and the system will return answers generated by the LLM based on the 
relevant document context.
"""
from fastapi import FastAPI
from pydantic import BaseModel
from embeddings import create_embeddings, get_context
from llm import ask_llm

app = FastAPI()

class QuestionRequest(BaseModel):
    user_name: str
    question: str

@app.post("/ask")
async def ask_question(request: QuestionRequest):
    # Assuming the document path is known
    document_path = 'C:\\Users\\HP\\OneDrive\\RAG_project\\data\\documento.docx'
    
    # Create embeddings if they don't exist
    create_embeddings(document_path)
    
    # Get context for the question
    context = get_context(request.question)
    
    # Generate response from LLM
    response = ask_llm(request.question, context)
    
    return {
        "user_name": request.user_name,
        "question": request.question,
        "response": response
    }